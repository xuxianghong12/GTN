{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c07555ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary package\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pdb\n",
    "import pickle, os\n",
    "from torch_geometric.utils import dense_to_sparse, f1_score, accuracy\n",
    "from torch_geometric.data import Data\n",
    "import torch_sparse\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# import files\n",
    "from parseargs import *\n",
    "args.dataset='ACM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d76f4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_886162/2204756402.py:6: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  edges = pickle.load(f)\n",
      "/tmp/ipykernel_886162/2204756402.py:6: DeprecationWarning: Please use `csc_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csc` namespace is deprecated.\n",
      "  edges = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "dataroot = 'data'\n",
    "with open(os.path.join(dataroot, args.dataset, 'node_features.pkl'),'rb') as f:\n",
    "    node_features = pickle.load(f)\n",
    "with open(os.path.join(dataroot, args.dataset, 'edges.pkl'),'rb') as f:\n",
    "    edges = pickle.load(f)\n",
    "with open(os.path.join(dataroot, args.dataset, 'labels.pkl'),'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c231e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prepare\n",
    "num_nodes = edges[0].shape[0]\n",
    "for i,edge in enumerate(edges):\n",
    "    if i ==0:\n",
    "        A = torch.from_numpy(edge.todense()).type(torch.FloatTensor).unsqueeze(-1)\n",
    "    else:\n",
    "        A = torch.cat([A,torch.from_numpy(edge.todense()).type(torch.FloatTensor).unsqueeze(-1)], dim=-1)\n",
    "A = torch.cat([A,torch.eye(num_nodes).type(torch.FloatTensor).unsqueeze(-1)], dim=-1)\n",
    "A = A.cuda()\n",
    "\n",
    "node_features = torch.from_numpy(node_features).type(torch.cuda.FloatTensor)\n",
    "train_node = torch.from_numpy(np.array(labels[0])[:,0]).type(torch.cuda.LongTensor)\n",
    "train_target = torch.from_numpy(np.array(labels[0])[:,1]).type(torch.cuda.LongTensor)\n",
    "\n",
    "valid_node = torch.from_numpy(np.array(labels[1])[:,0]).type(torch.cuda.LongTensor)\n",
    "valid_target = torch.from_numpy(np.array(labels[1])[:,1]).type(torch.cuda.LongTensor)\n",
    "test_node = torch.from_numpy(np.array(labels[2])[:,0]).type(torch.cuda.LongTensor)\n",
    "test_target = torch.from_numpy(np.array(labels[2])[:,1]).type(torch.cuda.LongTensor)\n",
    "\n",
    "\n",
    "num_classes = torch.max(train_target).item()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd88024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model define\n",
    "from model import GTN\n",
    "model = GTN(num_edge=A.shape[-1], num_channels=args.num_channels, w_in = node_features.shape[1], w_out = args.node_dim, num_class=num_classes, num_layers=args.num_layers, norm=args.norm)\n",
    "model = model.cuda()\n",
    "\n",
    "if args.adaptive_lr == 'false':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "else:\n",
    "    optimizer = torch.optim.Adam([{'params':model.weight},\n",
    "                                {'params':model.linear1.parameters()},\n",
    "                                {'params':model.linear2.parameters()},\n",
    "                                {\"params\":model.layers.parameters(), \"lr\":0.5}\n",
    "                                ], lr=0.005, weight_decay=0.001)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "best_val_loss = 10000\n",
    "best_test_loss = 10000\n",
    "best_train_loss = 10000\n",
    "best_train_f1 = 0\n",
    "best_val_f1 = 0\n",
    "best_test_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f844b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1\n",
      "Train - Loss: 1.1026039123535156, Macro_F1: 0.2510066032409668\n",
      "Valid - Loss: 1.064597725868225, Macro_F1: 0.3927691876888275\n",
      "Test - Loss: 1.064851999282837, Macro_F1: 0.42511463165283203\n",
      "\n",
      "Epoch:   2\n",
      "Train - Loss: 1.0621116161346436, Macro_F1: 0.44511276483535767\n",
      "Valid - Loss: 1.0005815029144287, Macro_F1: 0.4575720429420471\n",
      "Test - Loss: 1.0020924806594849, Macro_F1: 0.42890986800193787\n",
      "\n",
      "Epoch:   3\n",
      "Train - Loss: 0.9887065887451172, Macro_F1: 0.48181185126304626\n",
      "Valid - Loss: 0.9127394556999207, Macro_F1: 0.5152896642684937\n",
      "Test - Loss: 0.9191950559616089, Macro_F1: 0.4987413287162781\n",
      "\n",
      "Epoch:   4\n",
      "Train - Loss: 0.8885777592658997, Macro_F1: 0.5382675528526306\n",
      "Valid - Loss: 0.7590799331665039, Macro_F1: 0.8626084327697754\n",
      "Test - Loss: 0.7673485279083252, Macro_F1: 0.855971097946167\n",
      "\n",
      "Epoch:   5\n",
      "Train - Loss: 0.7249962687492371, Macro_F1: 0.9156365394592285\n",
      "Valid - Loss: 0.6255304217338562, Macro_F1: 0.9033226370811462\n",
      "Test - Loss: 0.6377333998680115, Macro_F1: 0.8835882544517517\n",
      "\n",
      "Epoch:   6\n",
      "Train - Loss: 0.5811274647712708, Macro_F1: 0.9349986910820007\n",
      "Valid - Loss: 0.519395112991333, Macro_F1: 0.8192808628082275\n",
      "Test - Loss: 0.5308486819267273, Macro_F1: 0.8356376886367798\n",
      "\n",
      "Epoch:   7\n",
      "Train - Loss: 0.4674653112888336, Macro_F1: 0.8848166465759277\n",
      "Valid - Loss: 0.4681076109409332, Macro_F1: 0.8208658695220947\n",
      "Test - Loss: 0.49286070466041565, Macro_F1: 0.7908236384391785\n",
      "\n",
      "Epoch:   8\n",
      "Train - Loss: 0.39690685272216797, Macro_F1: 0.8564743995666504\n",
      "Valid - Loss: 0.4396910071372986, Macro_F1: 0.7950064539909363\n",
      "Test - Loss: 0.4521014094352722, Macro_F1: 0.806139349937439\n",
      "\n",
      "Epoch:   9\n",
      "Train - Loss: 0.36759886145591736, Macro_F1: 0.8678358793258667\n",
      "Valid - Loss: 0.3043818771839142, Macro_F1: 0.9164237976074219\n",
      "Test - Loss: 0.3288751244544983, Macro_F1: 0.8883392810821533\n",
      "\n",
      "Epoch:   10\n",
      "Train - Loss: 0.2393474280834198, Macro_F1: 0.9465224146842957\n",
      "Valid - Loss: 0.3414040505886078, Macro_F1: 0.8502627611160278\n",
      "Test - Loss: 0.3752236068248749, Macro_F1: 0.8207412958145142\n",
      "\n",
      "Epoch:   11\n",
      "Train - Loss: 0.25811290740966797, Macro_F1: 0.8914560675621033\n",
      "Valid - Loss: 0.2478092908859253, Macro_F1: 0.9094311594963074\n",
      "Test - Loss: 0.27542969584465027, Macro_F1: 0.9004799723625183\n",
      "\n",
      "Epoch:   12\n",
      "Train - Loss: 0.18324187397956848, Macro_F1: 0.9480326175689697\n",
      "Valid - Loss: 0.2575262486934662, Macro_F1: 0.8926653861999512\n",
      "Test - Loss: 0.2870468199253082, Macro_F1: 0.888005256652832\n",
      "\n",
      "Epoch:   13\n",
      "Train - Loss: 0.18182507157325745, Macro_F1: 0.9464901685714722\n",
      "Valid - Loss: 0.23728136718273163, Macro_F1: 0.917294979095459\n",
      "Test - Loss: 0.27187487483024597, Macro_F1: 0.891302764415741\n",
      "\n",
      "Epoch:   14\n",
      "Train - Loss: 0.14277079701423645, Macro_F1: 0.9634339809417725\n",
      "Valid - Loss: 0.24852719902992249, Macro_F1: 0.8895697593688965\n",
      "Test - Loss: 0.2862459421157837, Macro_F1: 0.8756071329116821\n",
      "\n",
      "Epoch:   15\n",
      "Train - Loss: 0.13707278668880463, Macro_F1: 0.9583511352539062\n",
      "Valid - Loss: 0.18817439675331116, Macro_F1: 0.9132051467895508\n",
      "Test - Loss: 0.22579914331436157, Macro_F1: 0.9116522669792175\n",
      "\n",
      "Epoch:   16\n",
      "Train - Loss: 0.1018712967634201, Macro_F1: 0.9648367762565613\n",
      "Valid - Loss: 0.19750015437602997, Macro_F1: 0.9096464514732361\n",
      "Test - Loss: 0.23898369073867798, Macro_F1: 0.9074128866195679\n",
      "\n",
      "Epoch:   17\n",
      "Train - Loss: 0.1083461120724678, Macro_F1: 0.9613460302352905\n",
      "Valid - Loss: 0.1784869134426117, Macro_F1: 0.9298726916313171\n",
      "Test - Loss: 0.2206457555294037, Macro_F1: 0.9119285941123962\n",
      "\n",
      "Epoch:   18\n",
      "Train - Loss: 0.07725323736667633, Macro_F1: 0.9749247431755066\n",
      "Valid - Loss: 0.22072482109069824, Macro_F1: 0.9021353721618652\n",
      "Test - Loss: 0.26386964321136475, Macro_F1: 0.888298511505127\n",
      "\n",
      "Epoch:   19\n",
      "Train - Loss: 0.08069174736738205, Macro_F1: 0.9733240008354187\n",
      "Valid - Loss: 0.18353931605815887, Macro_F1: 0.9300300478935242\n",
      "Test - Loss: 0.22741875052452087, Macro_F1: 0.9086324572563171\n",
      "\n",
      "Epoch:   20\n",
      "Train - Loss: 0.05638977140188217, Macro_F1: 0.9883458018302917\n",
      "Valid - Loss: 0.1708785444498062, Macro_F1: 0.9199510812759399\n",
      "Test - Loss: 0.21777942776679993, Macro_F1: 0.919495701789856\n",
      "\n",
      "Epoch:   21\n",
      "Train - Loss: 0.05432109907269478, Macro_F1: 0.9833618998527527\n",
      "Valid - Loss: 0.17163516581058502, Macro_F1: 0.9199510812759399\n",
      "Test - Loss: 0.22007553279399872, Macro_F1: 0.9181846380233765\n",
      "\n",
      "Epoch:   22\n",
      "Train - Loss: 0.04839791730046272, Macro_F1: 0.9850268363952637\n",
      "Valid - Loss: 0.1762765347957611, Macro_F1: 0.9336020350456238\n",
      "Test - Loss: 0.2241932600736618, Macro_F1: 0.9170085787773132\n",
      "\n",
      "Epoch:   23\n",
      "Train - Loss: 0.034479472786188126, Macro_F1: 0.9933333396911621\n",
      "Valid - Loss: 0.2066619098186493, Macro_F1: 0.9134221076965332\n",
      "Test - Loss: 0.2540282905101776, Macro_F1: 0.905876636505127\n",
      "\n",
      "Epoch:   24\n",
      "Train - Loss: 0.03670947253704071, Macro_F1: 0.9916661977767944\n",
      "Valid - Loss: 0.1801721602678299, Macro_F1: 0.9302405714988708\n",
      "Test - Loss: 0.22930707037448883, Macro_F1: 0.916167140007019\n",
      "\n",
      "Epoch:   25\n",
      "Train - Loss: 0.024775689467787743, Macro_F1: 0.9950000047683716\n",
      "Valid - Loss: 0.16503435373306274, Macro_F1: 0.9367203116416931\n",
      "Test - Loss: 0.21727629005908966, Macro_F1: 0.9261390566825867\n",
      "\n",
      "Epoch:   26\n",
      "Train - Loss: 0.021925203502178192, Macro_F1: 0.9949997663497925\n",
      "Valid - Loss: 0.16812190413475037, Macro_F1: 0.9333135485649109\n",
      "Test - Loss: 0.22204609215259552, Macro_F1: 0.923867404460907\n",
      "\n",
      "Epoch:   27\n",
      "Train - Loss: 0.021147040650248528, Macro_F1: 0.9949997663497925\n",
      "Valid - Loss: 0.16656966507434845, Macro_F1: 0.9301061630249023\n",
      "Test - Loss: 0.22071769833564758, Macro_F1: 0.9217990636825562\n",
      "\n",
      "Epoch:   28\n",
      "Train - Loss: 0.01385215763002634, Macro_F1: 0.9983333349227905\n",
      "Valid - Loss: 0.18303082883358002, Macro_F1: 0.9264258146286011\n",
      "Test - Loss: 0.23613698780536652, Macro_F1: 0.9167333841323853\n",
      "\n",
      "Epoch:   29\n",
      "Train - Loss: 0.013083902187645435, Macro_F1: 1.0\n",
      "Valid - Loss: 0.19165444374084473, Macro_F1: 0.9297102689743042\n",
      "Test - Loss: 0.24514789879322052, Macro_F1: 0.9149497747421265\n",
      "\n",
      "Epoch:   30\n",
      "Train - Loss: 0.012714258395135403, Macro_F1: 1.0\n",
      "Valid - Loss: 0.17757318913936615, Macro_F1: 0.9266066551208496\n",
      "Test - Loss: 0.2333340346813202, Macro_F1: 0.9209994673728943\n",
      "\n",
      "Epoch:   31\n",
      "Train - Loss: 0.008592176251113415, Macro_F1: 1.0\n",
      "Valid - Loss: 0.17206625640392303, Macro_F1: 0.9334142208099365\n",
      "Test - Loss: 0.23032857477664948, Macro_F1: 0.9239255785942078\n",
      "\n",
      "Epoch:   32\n",
      "Train - Loss: 0.007373949512839317, Macro_F1: 1.0\n",
      "Valid - Loss: 0.17737159132957458, Macro_F1: 0.9300147891044617\n",
      "Test - Loss: 0.2368350327014923, Macro_F1: 0.9204515814781189\n",
      "\n",
      "Epoch:   33\n",
      "Train - Loss: 0.007861228659749031, Macro_F1: 1.0\n",
      "Valid - Loss: 0.17772401869297028, Macro_F1: 0.9267150163650513\n",
      "Test - Loss: 0.23729220032691956, Macro_F1: 0.9223856925964355\n",
      "\n",
      "Epoch:   34\n",
      "Train - Loss: 0.006448919884860516, Macro_F1: 1.0\n",
      "Valid - Loss: 0.17677411437034607, Macro_F1: 0.9334461092948914\n",
      "Test - Loss: 0.2355554699897766, Macro_F1: 0.9255762100219727\n",
      "\n",
      "Epoch:   35\n",
      "Train - Loss: 0.004660510923713446, Macro_F1: 1.0\n",
      "Valid - Loss: 0.18379847705364227, Macro_F1: 0.9234942197799683\n",
      "Test - Loss: 0.24120476841926575, Macro_F1: 0.9246469736099243\n",
      "\n",
      "Epoch:   36\n",
      "Train - Loss: 0.004329273477196693, Macro_F1: 1.0\n",
      "Valid - Loss: 0.19311262667179108, Macro_F1: 0.9236453771591187\n",
      "Test - Loss: 0.2496238499879837, Macro_F1: 0.922398030757904\n",
      "\n",
      "Epoch:   37\n",
      "Train - Loss: 0.004600405227392912, Macro_F1: 1.0\n",
      "Valid - Loss: 0.194011390209198, Macro_F1: 0.9204928874969482\n",
      "Test - Loss: 0.2507152557373047, Macro_F1: 0.9233108758926392\n",
      "\n",
      "Epoch:   38\n",
      "Train - Loss: 0.004106341395527124, Macro_F1: 1.0\n",
      "Valid - Loss: 0.18879523873329163, Macro_F1: 0.917171835899353\n",
      "Test - Loss: 0.24667179584503174, Macro_F1: 0.9232596158981323\n",
      "\n",
      "Epoch:   39\n",
      "Train - Loss: 0.0032215190585702658, Macro_F1: 1.0\n",
      "Valid - Loss: 0.1861642301082611, Macro_F1: 0.9270569682121277\n",
      "Test - Loss: 0.24557648599147797, Macro_F1: 0.9240741729736328\n",
      "\n",
      "Epoch:   40\n",
      "Train - Loss: 0.002818786073476076, Macro_F1: 1.0\n",
      "Valid - Loss: 0.1881989985704422, Macro_F1: 0.926838755607605\n",
      "Test - Loss: 0.2488073855638504, Macro_F1: 0.9258061647415161\n",
      "\n",
      "---------------Best Results--------------------\n",
      "Train - Loss: 0.024775689467787743, Macro_F1: 0.9950000047683716\n",
      "Valid - Loss: 0.16503435373306274, Macro_F1: 0.9367203116416931\n",
      "Test - Loss: 0.21727629005908966, Macro_F1: 0.9261390566825867\n"
     ]
    }
   ],
   "source": [
    "for i in range(args.epoch):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if param_group['lr'] > 0.005:\n",
    "            param_group['lr'] = param_group['lr'] * 0.9\n",
    "    print('Epoch:  ',i+1)\n",
    "    model.zero_grad()\n",
    "    # ====================\n",
    "    model.train()\n",
    "    # print(A.device, node_features.device, valid_node.device, valid_target.device)\n",
    "    loss,y_train,Ws = model(A, node_features, train_node, train_target)\n",
    "    train_f1 = torch.mean(f1_score(torch.argmax(y_train.detach(),dim=1), train_target, num_classes=num_classes)).cpu().numpy()\n",
    "    print('Train - Loss: {}, Macro_F1: {}'.format(loss.detach().cpu().numpy(), train_f1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # ====================\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss, y_valid,_ = model.forward(A, node_features, valid_node, valid_target)\n",
    "        val_f1 = torch.mean(f1_score(torch.argmax(y_valid,dim=1), valid_target, num_classes=num_classes)).cpu().numpy()\n",
    "        print('Valid - Loss: {}, Macro_F1: {}'.format(val_loss.detach().cpu().numpy(), val_f1))\n",
    "        test_loss, y_test,W = model.forward(A, node_features, test_node, test_target)\n",
    "        test_f1 = torch.mean(f1_score(torch.argmax(y_test,dim=1), test_target, num_classes=num_classes)).cpu().numpy()\n",
    "        print('Test - Loss: {}, Macro_F1: {}\\n'.format(test_loss.detach().cpu().numpy(), test_f1))\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_loss = val_loss.detach().cpu().numpy()\n",
    "        best_test_loss = test_loss.detach().cpu().numpy()\n",
    "        best_train_loss = loss.detach().cpu().numpy()\n",
    "        best_train_f1 = train_f1\n",
    "        best_val_f1 = val_f1\n",
    "        best_test_f1 = test_f1 \n",
    "print('---------------Best Results--------------------')\n",
    "print('Train - Loss: {}, Macro_F1: {}'.format(best_train_loss, best_train_f1))\n",
    "print('Valid - Loss: {}, Macro_F1: {}'.format(best_val_loss, best_val_f1))\n",
    "print('Test - Loss: {}, Macro_F1: {}'.format(best_test_loss, best_test_f1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
